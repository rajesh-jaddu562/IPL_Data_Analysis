{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "017c5ddf-67b6-4a61-b698-acbb413ae19d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType, DateType, BooleanType, DecimalType\n",
    "from pyspark.sql.functions import col, when, sum, avg, row_number \n",
    "from pyspark.sql.window import Window\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0bcb937-ef5e-4afc-bdb8-035a1a947d1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#Create Session\n",
    "spark = SparkSession.builder.appName(\"IPL Data Analysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "395f13b6-23e9-4b84-9436-d9313347560f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ball_by_ball_schema = StructType([\n",
    "    StructField(\"match_id\", IntegerType(), True),\n",
    "    StructField(\"over_id\", IntegerType(), True),\n",
    "    StructField(\"ball_id\", IntegerType(), True),\n",
    "    StructField(\"innings_no\", IntegerType(), True),\n",
    "    StructField(\"team_batting\", StringType(), True),\n",
    "    StructField(\"team_bowling\", StringType(), True),\n",
    "    StructField(\"striker_batting_position\", IntegerType(), True),\n",
    "    StructField(\"extra_type\", StringType(), True),\n",
    "    StructField(\"runs_scored\", IntegerType(), True),\n",
    "    StructField(\"extra_runs\", IntegerType(), True),\n",
    "    StructField(\"wides\", IntegerType(), True),\n",
    "    StructField(\"legbyes\", IntegerType(), True),\n",
    "    StructField(\"byes\", IntegerType(), True),\n",
    "    StructField(\"noballs\", IntegerType(), True),\n",
    "    StructField(\"penalty\", IntegerType(), True),\n",
    "    StructField(\"bowler_extras\", IntegerType(), True),\n",
    "    StructField(\"out_type\", StringType(), True),\n",
    "    StructField(\"caught\", BooleanType(), True),\n",
    "    StructField(\"bowled\", BooleanType(), True),\n",
    "    StructField(\"run_out\", BooleanType(), True),\n",
    "    StructField(\"lbw\", BooleanType(), True),\n",
    "    StructField(\"retired_hurt\", BooleanType(), True),\n",
    "    StructField(\"stumped\", BooleanType(), True),\n",
    "    StructField(\"caught_and_bowled\", BooleanType(), True),\n",
    "    StructField(\"hit_wicket\", BooleanType(), True),\n",
    "    StructField(\"obstructingfeild\", BooleanType(), True),\n",
    "    StructField(\"bowler_wicket\", BooleanType(), True),\n",
    "    StructField(\"match_date\", DateType(), True),\n",
    "    StructField(\"season\", IntegerType(), True),\n",
    "    StructField(\"striker\", IntegerType(), True),\n",
    "    StructField(\"non_striker\", IntegerType(), True),\n",
    "    StructField(\"bowler\", IntegerType(), True),\n",
    "    StructField(\"player_out\", IntegerType(), True),\n",
    "    StructField(\"fielders\", IntegerType(), True),\n",
    "    StructField(\"striker_match_sk\", IntegerType(), True),\n",
    "    StructField(\"strikersk\", IntegerType(), True),\n",
    "    StructField(\"nonstriker_match_sk\", IntegerType(), True),\n",
    "    StructField(\"nonstriker_sk\", IntegerType(), True),\n",
    "    StructField(\"fielder_match_sk\", IntegerType(), True),\n",
    "    StructField(\"fielder_sk\", IntegerType(), True),\n",
    "    StructField(\"bowler_match_sk\", IntegerType(), True),\n",
    "    StructField(\"bowler_sk\", IntegerType(), True),\n",
    "    StructField(\"playerout_match_sk\", IntegerType(), True),\n",
    "    StructField(\"battingteam_sk\", IntegerType(), True),\n",
    "    StructField(\"bowlingteam_sk\", IntegerType(), True),\n",
    "    StructField(\"keeper_catch\", BooleanType(), True),\n",
    "    StructField(\"player_out_sk\", IntegerType(), True),\n",
    "    StructField(\"matchdatesk\", DateType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b086841-cd5d-4640-9d04-601fe306d189",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ball_by_ball_df = spark.read.schema(ball_by_ball_schema).format(\"csv\").option(\"header\",\"true\").load(\"s3://ipl-data-analysis-project/Ball_By_Ball.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "893dd81d-9bab-4597-a3cd-1c05a8531d92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "match_schema = StructType([\n",
    "    StructField(\"match_sk\", IntegerType(), True),\n",
    "    StructField(\"match_id\", IntegerType(), True),\n",
    "    StructField(\"team1\", StringType(), True),\n",
    "    StructField(\"team2\", StringType(), True),\n",
    "    StructField(\"match_date\", DateType(), True),\n",
    "    StructField(\"season_year\", IntegerType(), True),\n",
    "    StructField(\"venue_name\", StringType(), True),\n",
    "    StructField(\"city_name\", StringType(), True),\n",
    "    StructField(\"country_name\", StringType(), True),\n",
    "    StructField(\"toss_winner\", StringType(), True),\n",
    "    StructField(\"match_winner\", StringType(), True),\n",
    "    StructField(\"toss_name\", StringType(), True),\n",
    "    StructField(\"win_type\", StringType(), True),\n",
    "    StructField(\"outcome_type\", StringType(), True),\n",
    "    StructField(\"manofmach\", StringType(), True),\n",
    "    StructField(\"win_margin\", IntegerType(), True),\n",
    "    StructField(\"country_id\", IntegerType(), True)\n",
    "])\n",
    "match_df = spark.read.schema(match_schema).format(\"csv\").option(\"header\",\"true\").load(\"s3://ipl-data-analysis-project/Match.csv\")\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d1606eb-793a-4267-9f91-95874388ebe2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "player_schema = StructType([\n",
    "    StructField(\"player_sk\", IntegerType(), True),\n",
    "    StructField(\"player_id\", IntegerType(), True),\n",
    "    StructField(\"player_name\", StringType(), True),\n",
    "    StructField(\"dob\", DateType(), True),\n",
    "    StructField(\"batting_hand\", StringType(), True),\n",
    "    StructField(\"bowling_skill\", StringType(), True),\n",
    "    StructField(\"country_name\", StringType(), True)\n",
    "])\n",
    "\n",
    "player_df = spark.read.schema(player_schema).format(\"csv\").option(\"header\",\"true\").load(\"s3://ipl-data-analysis-project/Player.csv\")\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "001bfa89-4789-4bfd-bec8-cc1df1aa9b47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "player_match_schema = StructType([\n",
    "    StructField(\"player_match_sk\", IntegerType(), True),\n",
    "    StructField(\"playermatch_key\", DecimalType(), True),\n",
    "    StructField(\"match_id\", IntegerType(), True),\n",
    "    StructField(\"player_id\", IntegerType(), True),\n",
    "    StructField(\"player_name\", StringType(), True),\n",
    "    StructField(\"dob\", DateType(), True),\n",
    "    StructField(\"batting_hand\", StringType(), True),\n",
    "    StructField(\"bowling_skill\", StringType(), True),\n",
    "    StructField(\"country_name\", StringType(), True),\n",
    "    StructField(\"role_desc\", StringType(), True),\n",
    "    StructField(\"player_team\", StringType(), True),\n",
    "    StructField(\"opposit_team\", StringType(), True),\n",
    "    StructField(\"season_year\", IntegerType(), True),\n",
    "    StructField(\"is_manofthematch\", BooleanType(), True),\n",
    "    StructField(\"age_as_on_match\", IntegerType(), True),\n",
    "    StructField(\"isplayers_team_won\", BooleanType(), True),\n",
    "    StructField(\"batting_status\", StringType(), True),\n",
    "    StructField(\"bowling_status\", StringType(), True),\n",
    "    StructField(\"player_captain\", StringType(), True),\n",
    "    StructField(\"opposit_captain\", StringType(), True),\n",
    "    StructField(\"player_keeper\", StringType(), True),\n",
    "    StructField(\"opposit_keeper\", StringType(), True)\n",
    "])\n",
    "\n",
    "player_match_df = spark.read.schema(player_match_schema).format(\"csv\").option(\"header\",\"true\").load(\"s3://ipl-data-analysis-project/Player_match.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6277b1da-9211-42d8-a6de-f21f798e5f73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "team_schema = StructType([\n",
    "    StructField(\"team_sk\", IntegerType(), True),\n",
    "    StructField(\"team_id\", IntegerType(), True),\n",
    "    StructField(\"team_name\", StringType(), True)\n",
    "])\n",
    "\n",
    "team_df = spark.read.schema(team_schema).format(\"csv\").option(\"header\",\"true\").load(\"s3://ipl-data-analysis-project/Team.csv\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f81c9a04-e708-4b73-8415-af70a4b76dbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "               #Transformations on Ball_by_Ball DataFrame\n",
    "\n",
    "#Aggregation: Calculate the total and average runs scored in each match and inning\n",
    "total_and_avg_runs = ball_by_ball_df.groupBy(\"match_id\", \"innings_no\").agg(\n",
    "    sum(\"runs_scored\").alias(\"total_runs\"),\n",
    "    avg(\"runs_scored\").alias(\"average_runs\")\n",
    ")\n",
    "\n",
    "# Window Function: Calculate running total of runs in each match for each over\n",
    "windowSpec = Window.partitionBy(\"match_id\",\"innings_no\").orderBy(\"over_id\")\n",
    "\n",
    "ball_by_ball_df = ball_by_ball_df.withColumn(\n",
    "    \"running_total_runs\",\n",
    "    sum(\"runs_scored\").over(windowSpec)\n",
    ")\n",
    "\n",
    "\n",
    "# Conditional Column: Flag for high impact balls (either a wicket or more than 6 runs including extras)\n",
    "ball_by_ball_df = ball_by_ball_df.withColumn(\n",
    "    \"high_impact\",\n",
    "    when((col(\"runs_scored\") + col(\"extra_runs\") > 6) | (col(\"bowler_wicket\") == True), True).otherwise(False)\n",
    ")\n",
    "ball_by_ball_df.show(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dac98284-2907-4cd2-9dc7-369748873f02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "                  #Transformations on Match DataFrame\n",
    "\n",
    "# High margin win: categorizing win margins into 'high', 'medium', and 'low'\n",
    "match_df = match_df.withColumn(\n",
    "    \"win_margin_category\",\n",
    "    when(col(\"win_margin\") >= 100, \"High\")\n",
    "    .when((col(\"win_margin\") >= 50) & (col(\"win_margin\") < 100), \"Medium\")\n",
    "    .otherwise(\"Low\")\n",
    ")\n",
    "\n",
    "# Analyze the impact of the toss: who wins the toss and the match\n",
    "match_df = match_df.withColumn(\n",
    "    \"toss_match_winner\",\n",
    "    when(col(\"toss_winner\") == col(\"match_winner\"), \"Yes\").otherwise(\"No\")\n",
    ")\n",
    "\n",
    "# Show the enhanced match DataFrame\n",
    "match_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9afeb9b0-606f-4184-9a0b-d3c9eeee3407",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "              #Transformations on Player DataFrame\n",
    "\n",
    "from pyspark.sql.functions import lower, regexp_replace\n",
    "\n",
    "# Normalize and clean player names\n",
    "player_df = player_df.withColumn(\"player_name\", lower(regexp_replace(\"player_name\", \"[^a-zA-Z0-9 ]\", \"\")))\n",
    "\n",
    "# Handle missing values in 'batting_hand' and 'bowling_skill' with a default 'unknown'\n",
    "player_df = player_df.na.fill({\"batting_hand\": \"unknown\", \"bowling_skill\": \"unknown\"})\n",
    "\n",
    "# Categorizing players based on batting hand\n",
    "player_df = player_df.withColumn(\n",
    "    \"batting_style\",\n",
    "    when(col(\"batting_hand\").contains(\"Left-hand bat\"), \"Left-Handed\").otherwise(\"Right-Handed\")\n",
    ")\n",
    "\n",
    "# Show the modified player DataFrame\n",
    "player_df.show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bcacf65-e2ad-4ade-b23a-d0638e5b223a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, current_date, expr,year\n",
    "\n",
    "# Add a 'veteran_status' column based on player age\n",
    "player_match_df = player_match_df.withColumn(\n",
    "    \"veteran_status\",\n",
    "    when(col(\"age_as_on_match\") >= 35, \"Veteran\").otherwise(\"Non-Veteran\")\n",
    ")\n",
    "\n",
    "# Dynamic column to calculate years since debut\n",
    "player_match_df = player_match_df.withColumn(\n",
    "    \"years_since_debut\",\n",
    "    (year(current_date()) - col(\"season_year\"))\n",
    ")\n",
    "\n",
    "# Show the enriched DataFrame\n",
    "player_match_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6aa399f1-0561-4b2a-986a-10dc4e58e2f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ball_by_ball_df.createOrReplaceTempView(\"ball_by_ball\")\n",
    "match_df.createOrReplaceTempView(\"match\")\n",
    "player_df.createOrReplaceTempView(\"player\")\n",
    "player_match_df.createOrReplaceTempView(\"player_match\")\n",
    "team_df.createOrReplaceTempView(\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a36b28cf-9e4e-4374-bdf7-1f9bff624ea6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ball_by_ball_df.columns\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4ef322e-c02a-460b-81e7-04bd31d3fb81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Highest Run Getter In Each Season**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71d5af6c-d661-4831-a7bb-e76d825e4802",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1761148638569}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_scoring_batsmen_per_season = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  player_name,\n",
    "  season_year,\n",
    "  total_runs\n",
    "FROM (\n",
    "  SELECT\n",
    "    p.player_name,\n",
    "    m.season_year,\n",
    "    SUM(b.runs_scored) AS total_runs,\n",
    "    RANK() OVER (\n",
    "      PARTITION BY m.season_year\n",
    "      ORDER BY SUM(b.runs_scored) DESC\n",
    "    ) AS rnk\n",
    "  FROM ball_by_ball b\n",
    "  JOIN match m ON b.match_id = m.match_id\n",
    "  JOIN player_match pm ON m.match_id = pm.match_id AND b.striker = pm.player_id\n",
    "  JOIN player p ON p.player_id = pm.player_id\n",
    "  GROUP BY p.player_name, m.season_year\n",
    ")\n",
    "WHERE rnk IN (1)\n",
    "ORDER BY season_year\n",
    "\"\"\")\n",
    "\n",
    "display(top_scoring_batsmen_per_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c512ec6c-b616-42b1-853f-2d722efd35e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Economic Bowler of each season Who Played atleast 7 matches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09d71f6e-38ff-4453-ad6e-bc7c3076108e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "most_economical_bowler_per_season = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  season_year,\n",
    "  player_name,\n",
    "  ROUND(economy, 2) AS economy\n",
    "FROM (\n",
    "  SELECT\n",
    "    m.season_year,\n",
    "    p.player_name,\n",
    "    SUM(CASE WHEN b.bowler_wicket IS NOT NULL THEN 1 ELSE 0 END) AS total_wickets,\n",
    "    SUM(b.runs_scored) * 6.0 / COUNT(*) AS economy,\n",
    "    RANK() OVER (\n",
    "      PARTITION BY m.season_year\n",
    "      ORDER BY SUM(b.runs_scored) * 6.0 / COUNT(*) ASC\n",
    "    ) AS rnk\n",
    "  FROM ball_by_ball b\n",
    "  JOIN match m ON b.match_id = m.match_id\n",
    "  JOIN player_match pm ON b.match_id = pm.match_id AND b.bowler = pm.player_id\n",
    "  JOIN player p ON pm.player_id = p.player_id\n",
    "  GROUP BY m.season_year, p.player_name\n",
    "   HAVING COUNT(DISTINCT m.match_id) >= 7\n",
    ")\n",
    "WHERE rnk in (1)\n",
    "ORDER BY season_year\n",
    "\"\"\")\n",
    "\n",
    "display(most_economical_bowler_per_season)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d75a7ab9-3431-402e-9575-4ba4d19db437",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " **Top Wicket Taker In Each Season**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be2d2f94-fcd9-4185-84f2-25ebc560be46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%sql\n",
    "SELECT\n",
    "  season_year,\n",
    "  player_name,\n",
    "  total_wickets\n",
    "FROM (\n",
    "  SELECT\n",
    "    m.season_year,\n",
    "    p.player_name,\n",
    "    SUM(CASE WHEN b.out_type IS NOT NULL AND b.out_type != 'Not Applicable' THEN 1 ELSE 0 END) AS total_wickets,\n",
    "    DENSE_RANK() OVER (\n",
    "      PARTITION BY m.season_year\n",
    "      ORDER BY SUM(CASE WHEN b.out_type IS NOT NULL AND b.out_type != 'Not Applicable' THEN 1 ELSE 0 END) DESC\n",
    "    ) AS rnk\n",
    "  FROM ball_by_ball b\n",
    "  JOIN match m ON b.match_id = m.match_id\n",
    "  JOIN player p ON b.bowler = p.player_id\n",
    "  GROUP BY m.season_year, p.player_name\n",
    ")\n",
    "WHERE rnk = 1\n",
    "ORDER BY season_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1860885c-4f57-450e-94cf-052a996ac1b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**HIGHEST INDIVIDUAL SCORE FROM EACH SEASON**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90b9f3d7-c6ae-480f-892d-a3d98bb1cc3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "highest_individual_score_per_season = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  season_year,\n",
    "  player_name,\n",
    "  max_score\n",
    "FROM (\n",
    "  SELECT\n",
    "    m.season_year,\n",
    "    p.player_name,\n",
    "    SUM(b.runs_scored) AS max_score,\n",
    "    RANK() OVER (\n",
    "      PARTITION BY m.season_year\n",
    "      ORDER BY SUM(b.runs_scored) DESC\n",
    "    ) AS rnk\n",
    "  FROM ball_by_ball b\n",
    "  JOIN match m ON b.match_id = m.match_id\n",
    "  JOIN player_match pm ON m.match_id = pm.match_id AND b.striker = pm.player_id\n",
    "  JOIN player p ON p.player_id = pm.player_id\n",
    "  GROUP BY m.season_year, p.player_name, b.match_id, b.innings_no\n",
    ")\n",
    "WHERE rnk = 1\n",
    "ORDER BY season_year\n",
    "\"\"\")\n",
    "\n",
    "display(highest_individual_score_per_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0520349e-0d6f-45f9-b1ff-0c10d4a04c78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**TOSS IMPACT ON MATCHES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dff24a96-7438-4d28-a6d2-5228fd7ba0a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "toss_impact_individual_matches = spark.sql(\"\"\"\n",
    "SELECT m.match_id, m.toss_winner, m.toss_name, m.match_winner,\n",
    "       CASE WHEN m.toss_winner = m.match_winner THEN 'Won' ELSE 'Lost' END AS match_outcome\n",
    "FROM match m\n",
    "WHERE m.toss_name IS NOT NULL\n",
    "ORDER BY m.match_id\n",
    "\"\"\")\n",
    "toss_impact_individual_matches.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17ae738b-4d74-45fe-8f6b-6da4937a67f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Top 10 Best Economic Bowlers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1584cbdd-fa5a-4ee8-8dbd-6e991b1bdac6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert 'economy' column to numeric, coercing errors to NaN\n",
    "import pandas as pd\n",
    "economical_bowlers_pd['economy'] = pd.to_numeric(\n",
    "    economical_bowlers_pd['economy'],\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "top_economical_bowlers = economical_bowlers_pd.nsmallest(10, 'economy')\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(\n",
    "    top_economical_bowlers['player_name'],\n",
    "    top_economical_bowlers['economy'],\n",
    "    color='skyblue'\n",
    ")\n",
    "plt.xlabel('Bowler Name')\n",
    "plt.ylabel('Economy Rate')\n",
    "plt.title('Most Economical Bowlers Top 10')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c4659f2-acab-44bd-922d-f9b76332d86f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Distribution of Scores by Venue**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "859c42ab-567a-45b9-82ff-b948b4774334",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Execute SQL Query\n",
    "scores_by_venue = spark.sql(\"\"\"\n",
    "SELECT venue_name, AVG(total_runs) AS average_score, MAX(total_runs) AS highest_score\n",
    "FROM (\n",
    "    SELECT ball_by_ball.match_id, match.venue_name, SUM(runs_scored) AS total_runs\n",
    "    FROM ball_by_ball\n",
    "    JOIN match ON ball_by_ball.match_id = match.match_id\n",
    "    GROUP BY ball_by_ball.match_id, match.venue_name\n",
    ")\n",
    "GROUP BY venue_name\n",
    "ORDER BY average_score DESC\n",
    "\"\"\")\n",
    "# Convert to Pandas DataFrame\n",
    "scores_by_venue_pd = scores_by_venue.toPandas()\n",
    "import seaborn as sns\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='average_score', y='venue_name', data=scores_by_venue_pd)\n",
    "plt.title('Distribution of Scores by Venue')\n",
    "plt.xlabel('Average Score')\n",
    "plt.ylabel('Venue')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8380644727576679,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "IPL_DATA_ANALYSIS_SPARK",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
